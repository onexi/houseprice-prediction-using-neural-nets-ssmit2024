{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4712</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>121600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10659</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>COD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>136500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>185000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>30</td>\n",
       "      <td>RM</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9786</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>91000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>64.0</td>\n",
       "      <td>6762</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>206000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0       1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1       2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2       3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3       4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4       5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "..    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "995   996          50       RL         51.0     4712   Pave   NaN      IR1   \n",
       "996   997          20       RL          NaN    10659   Pave   NaN      IR1   \n",
       "997   998          20       RL          NaN    11717   Pave   NaN      IR1   \n",
       "998   999          30       RM         60.0     9786   Pave   NaN      Reg   \n",
       "999  1000          20       RL         64.0     6762   Pave   NaN      Reg   \n",
       "\n",
       "    LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0           Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1           Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2           Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "3           Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "4           Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "..          ...       ...  ...      ...    ...    ...         ...     ...   \n",
       "995         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "996         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "997         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "998         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "999         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "    MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0        2   2008        WD         Normal     208500  \n",
       "1        5   2007        WD         Normal     181500  \n",
       "2        9   2008        WD         Normal     223500  \n",
       "3        2   2006        WD        Abnorml     140000  \n",
       "4       12   2008        WD         Normal     250000  \n",
       "..     ...    ...       ...            ...        ...  \n",
       "995      8   2006        WD        Abnorml     121600  \n",
       "996      1   2006       COD         Normal     136500  \n",
       "997      2   2009        WD         Normal     185000  \n",
       "998      5   2006        WD         Normal      91000  \n",
       "999      2   2010        WD         Normal     206000  \n",
       "\n",
       "[1000 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1. Load the dataset\n",
    "# -----------------------------\n",
    "# Replace 'house_prices.csv' with the path to your dataset.\n",
    "data = pd.read_csv('train.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 2. Data Cleaning\n",
    "# -----------------------------\n",
    "# Select only numeric columns that have no missing data.\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "clean_numeric_cols = [col for col in numeric_cols if data[col].isna().sum() == 0]\n",
    "data_clean = data[clean_numeric_cols]\n",
    "\n",
    "# Ensure that the target column 'price' is present.\n",
    "if 'SalePrice' not in data_clean.columns:\n",
    "    raise ValueError(\"The target column 'price' is not present in the complete numeric data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected top 5 features: ['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF']\n",
      "Epoch [100/2000], Loss: 7386752081.9200\n",
      "Epoch [200/2000], Loss: 3133550177.2800\n",
      "Epoch [300/2000], Loss: 1489642284.8000\n",
      "Epoch [400/2000], Loss: 1330615632.6400\n",
      "Epoch [500/2000], Loss: 1285745509.1200\n",
      "Epoch [600/2000], Loss: 1258883957.7600\n",
      "Epoch [700/2000], Loss: 1241085539.8400\n",
      "Epoch [800/2000], Loss: 1229159741.4400\n",
      "Epoch [900/2000], Loss: 1220857146.8800\n",
      "Epoch [1000/2000], Loss: 1217095535.3600\n",
      "Epoch [1100/2000], Loss: 1211245048.3200\n",
      "Epoch [1200/2000], Loss: 1208739080.9600\n",
      "Epoch [1300/2000], Loss: 1204897529.6000\n",
      "Epoch [1400/2000], Loss: 1202925579.5200\n",
      "Epoch [1500/2000], Loss: 1200789841.9200\n",
      "Epoch [1600/2000], Loss: 1199190416.6400\n",
      "Epoch [1700/2000], Loss: 1198596357.1200\n",
      "Epoch [1800/2000], Loss: 1197158551.0400\n",
      "Epoch [1900/2000], Loss: 1195143073.2800\n",
      "Epoch [2000/2000], Loss: 1193230533.1200\n",
      "Test Mean Squared Error: 867080512.0\n",
      "\n",
      "Test MSE (scikit-learn): 867080565.7001562\n",
      "In-sample R^2: 0.8292\n",
      "Out-of-sample R^2: 0.7924\n"
     ]
    }
   ],
   "source": [
    "NVAR = 5\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Feature Selection\n",
    "# -----------------------------\n",
    "# Compute the correlation matrix using only the cleaned numeric data.\n",
    "corr_matrix = data_clean.corr()\n",
    "\n",
    "# Compute absolute correlations of features with the target and drop the target itself.\n",
    "target_corr = corr_matrix['SalePrice'].drop('SalePrice').abs().sort_values(ascending=False)\n",
    "# print(target_corr)\n",
    "\n",
    "# Select only the top NVAR features with the highest correlation with 'SalesPrice'\n",
    "top_features = target_corr.head(NVAR).index\n",
    "print(f\"Selected top {NVAR} features:\", list(top_features))\n",
    "\n",
    "# Define input features (X) and target variable (y).\n",
    "X = data_clean[top_features].values\n",
    "y = data_clean['SalePrice'].values.reshape(-1, 1)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Data Preprocessing\n",
    "# -----------------------------\n",
    "# Split the data into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features to improve training stability.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert the numpy arrays to PyTorch tensors.\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create a TensorDataset and DataLoader for batch processing.\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Define the Neural Network Model\n",
    "# -----------------------------\n",
    "class HousePriceModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(HousePriceModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)  # Output layer for regression\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = HousePriceModel(input_dim=X_train.shape[1]).to(device)\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Set Up Loss Function and Optimizer\n",
    "# -----------------------------\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Train the Model\n",
    "# -----------------------------\n",
    "num_epochs = 2000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * batch_X.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 8. Evaluate the Model\n",
    "# -----------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor.to(device))\n",
    "    test_loss = criterion(predictions, y_test_tensor.to(device)).item()\n",
    "    print(\"Test Mean Squared Error:\", test_loss)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# Optionally, to evaluate using scikit-learn's MSE:\n",
    "predictions_np = predictions.cpu().numpy()\n",
    "mse = mean_squared_error(y_test, predictions_np)\n",
    "print(\"Test MSE (scikit-learn):\", mse)\n",
    "# Test Mean Squared Error: 935741376.0\n",
    "\n",
    "# Calculate in-sample R^2 value\n",
    "y_train_pred = model(X_train_tensor).detach().numpy()\n",
    "ss_total = np.sum((y_train - np.mean(y_train))**2)\n",
    "ss_residual = np.sum((y_train - y_train_pred)**2)\n",
    "r2_score = 1 - (ss_residual / ss_total)\n",
    "print(f'In-sample R^2: {r2_score:.4f}')\n",
    "\n",
    "# Calculate out-of-sample R^2 value\n",
    "y_test_pred = model(X_test_tensor).detach().numpy()\n",
    "ss_total_test = np.sum((y_test - np.mean(y_test))**2)\n",
    "ss_residual_test = np.sum((y_test - y_test_pred)**2)\n",
    "r2_score_test = 1 - (ss_residual_test / ss_total_test)\n",
    "print(f'Out-of-sample R^2: {r2_score_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"408pt\" height=\"571pt\"\n",
       " viewBox=\"0.00 0.00 408.00 571.25\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 567.25)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-567.25 404,-567.25 404,4 -4,4\"/>\n",
       "<!-- 13280306880 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>13280306880</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"222,-32.75 164,-32.75 164,0 222,0 222,-32.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"193\" y=\"-7.25\" font-family=\"monospace\" font-size=\"10.00\"> (1, 1)</text>\n",
       "</g>\n",
       "<!-- 13237288480 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>13237288480</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"243,-89.5 143,-89.5 143,-68.75 243,-68.75 243,-89.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"193\" y=\"-76\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n",
       "</g>\n",
       "<!-- 13237288480&#45;&gt;13280306880 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>13237288480&#45;&gt;13280306880</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M193,-68.36C193,-61.89 193,-53.05 193,-44.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"196.5,-44.55 193,-34.55 189.5,-44.55 196.5,-44.55\"/>\n",
       "</g>\n",
       "<!-- 13236214784 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>13236214784</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"128,-146.25 28,-146.25 28,-125.5 128,-125.5 128,-146.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"78\" y=\"-132.75\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 13236214784&#45;&gt;13237288480 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>13236214784&#45;&gt;13237288480</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M98.56,-125.09C116.3,-116.64 142.18,-104.32 162.37,-94.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"163.73,-97.94 171.25,-90.48 160.72,-91.62 163.73,-97.94\"/>\n",
       "</g>\n",
       "<!-- 13280317264 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>13280317264</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"110,-215.75 46,-215.75 46,-182.25 110,-182.25 110,-215.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"78\" y=\"-202.25\" font-family=\"monospace\" font-size=\"10.00\">fc3.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"78\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 13280317264&#45;&gt;13236214784 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>13280317264&#45;&gt;13236214784</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M78,-181.94C78,-174.6 78,-165.82 78,-157.96\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"81.5,-158.23 78,-148.23 74.5,-158.23 81.5,-158.23\"/>\n",
       "</g>\n",
       "<!-- 13236217184 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>13236217184</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"240,-146.25 146,-146.25 146,-125.5 240,-125.5 240,-146.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"193\" y=\"-132.75\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 13236217184&#45;&gt;13237288480 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>13236217184&#45;&gt;13237288480</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M193,-125.09C193,-118.47 193,-109.47 193,-101.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"196.5,-101.34 193,-91.34 189.5,-101.34 196.5,-101.34\"/>\n",
       "</g>\n",
       "<!-- 13236213296 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>13236213296</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"235,-209.38 135,-209.38 135,-188.62 235,-188.62 235,-209.38\"/>\n",
       "<text text-anchor=\"middle\" x=\"185\" y=\"-195.88\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n",
       "</g>\n",
       "<!-- 13236213296&#45;&gt;13236217184 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>13236213296&#45;&gt;13236217184</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M186.29,-188.18C187.35,-180.02 188.91,-168.13 190.25,-157.85\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"193.72,-158.34 191.55,-147.97 186.78,-157.43 193.72,-158.34\"/>\n",
       "</g>\n",
       "<!-- 13236223232 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>13236223232</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"100,-278.88 0,-278.88 0,-258.12 100,-258.12 100,-278.88\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-265.38\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 13236223232&#45;&gt;13236213296 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>13236223232&#45;&gt;13236213296</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M69.63,-257.68C92.13,-246.44 129.24,-227.88 155.28,-214.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.61,-218.11 163.99,-210.5 153.48,-211.85 156.61,-218.11\"/>\n",
       "</g>\n",
       "<!-- 13280313200 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>13280313200</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"82,-354.75 18,-354.75 18,-321.25 82,-321.25 82,-354.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-341.25\" font-family=\"monospace\" font-size=\"10.00\">fc2.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-328.5\" font-family=\"monospace\" font-size=\"10.00\"> (32)</text>\n",
       "</g>\n",
       "<!-- 13280313200&#45;&gt;13236223232 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>13280313200&#45;&gt;13236223232</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-321C50,-311.9 50,-300.39 50,-290.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-290.84 50,-280.84 46.5,-290.84 53.5,-290.84\"/>\n",
       "</g>\n",
       "<!-- 13236223376 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>13236223376</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"212,-278.88 118,-278.88 118,-258.12 212,-258.12 212,-278.88\"/>\n",
       "<text text-anchor=\"middle\" x=\"165\" y=\"-265.38\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 13236223376&#45;&gt;13236213296 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>13236223376&#45;&gt;13236213296</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M167.87,-257.83C170.75,-248.1 175.28,-232.82 178.96,-220.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"182.22,-221.69 181.71,-211.1 175.51,-219.7 182.22,-221.69\"/>\n",
       "</g>\n",
       "<!-- 13236221120 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>13236221120</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"207,-348.38 107,-348.38 107,-327.62 207,-327.62 207,-348.38\"/>\n",
       "<text text-anchor=\"middle\" x=\"157\" y=\"-334.88\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n",
       "</g>\n",
       "<!-- 13236221120&#45;&gt;13236223376 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>13236221120&#45;&gt;13236223376</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.15,-327.33C159.29,-317.71 161.07,-302.63 162.54,-290.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"165.98,-291 163.68,-280.66 159.03,-290.17 165.98,-291\"/>\n",
       "</g>\n",
       "<!-- 13236214544 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>13236214544</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"113,-417.88 13,-417.88 13,-397.12 113,-397.12 113,-417.88\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-404.38\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 13236214544&#45;&gt;13236221120 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>13236214544&#45;&gt;13236221120</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M76.47,-396.83C91.46,-386.06 115.95,-368.48 133.99,-355.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.94,-358.43 142.02,-349.76 131.86,-352.75 135.94,-358.43\"/>\n",
       "</g>\n",
       "<!-- 13280304000 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>13280304000</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"95,-493.75 31,-493.75 31,-460.25 95,-460.25 95,-493.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-480.25\" font-family=\"monospace\" font-size=\"10.00\">fc1.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-467.5\" font-family=\"monospace\" font-size=\"10.00\"> (64)</text>\n",
       "</g>\n",
       "<!-- 13280304000&#45;&gt;13236214544 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>13280304000&#45;&gt;13236214544</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M63,-460C63,-450.9 63,-439.39 63,-429.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"66.5,-429.84 63,-419.84 59.5,-429.84 66.5,-429.84\"/>\n",
       "</g>\n",
       "<!-- 13236214688 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>13236214688</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"207,-417.88 131,-417.88 131,-397.12 207,-397.12 207,-417.88\"/>\n",
       "<text text-anchor=\"middle\" x=\"169\" y=\"-404.38\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n",
       "</g>\n",
       "<!-- 13236214688&#45;&gt;13236221120 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>13236214688&#45;&gt;13236221120</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M167.28,-396.83C165.57,-387.21 162.89,-372.13 160.7,-359.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"164.18,-359.38 158.98,-350.14 157.29,-360.6 164.18,-359.38\"/>\n",
       "</g>\n",
       "<!-- 13236222224 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13236222224</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"219,-487.38 119,-487.38 119,-466.62 219,-466.62 219,-487.38\"/>\n",
       "<text text-anchor=\"middle\" x=\"169\" y=\"-473.88\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 13236222224&#45;&gt;13236214688 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>13236222224&#45;&gt;13236214688</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M169,-466.33C169,-456.71 169,-441.63 169,-429.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"172.5,-429.67 169,-419.67 165.5,-429.67 172.5,-429.67\"/>\n",
       "</g>\n",
       "<!-- 13280304880 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>13280304880</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"207,-563.25 131,-563.25 131,-529.75 207,-529.75 207,-563.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"169\" y=\"-549.75\" font-family=\"monospace\" font-size=\"10.00\">fc1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"169\" y=\"-537\" font-family=\"monospace\" font-size=\"10.00\"> (64, 5)</text>\n",
       "</g>\n",
       "<!-- 13280304880&#45;&gt;13236222224 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>13280304880&#45;&gt;13236222224</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M169,-529.5C169,-520.4 169,-508.89 169,-499.07\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"172.5,-499.34 169,-489.34 165.5,-499.34 172.5,-499.34\"/>\n",
       "</g>\n",
       "<!-- 13236222320 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>13236222320</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"306,-278.88 230,-278.88 230,-258.12 306,-258.12 306,-278.88\"/>\n",
       "<text text-anchor=\"middle\" x=\"268\" y=\"-265.38\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n",
       "</g>\n",
       "<!-- 13236222320&#45;&gt;13236213296 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>13236222320&#45;&gt;13236213296</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M256.11,-257.83C242.99,-247.16 221.65,-229.8 205.76,-216.88\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"208.28,-214.42 198.31,-210.83 203.86,-219.85 208.28,-214.42\"/>\n",
       "</g>\n",
       "<!-- 13236213008 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>13236213008</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"325,-348.38 225,-348.38 225,-327.62 325,-327.62 325,-348.38\"/>\n",
       "<text text-anchor=\"middle\" x=\"275\" y=\"-334.88\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 13236213008&#45;&gt;13236222320 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>13236213008&#45;&gt;13236222320</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M274,-327.33C273,-317.71 271.44,-302.63 270.16,-290.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"273.67,-290.24 269.16,-280.66 266.71,-290.97 273.67,-290.24\"/>\n",
       "</g>\n",
       "<!-- 13280311920 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>13280311920</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"313,-424.25 237,-424.25 237,-390.75 313,-390.75 313,-424.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"275\" y=\"-410.75\" font-family=\"monospace\" font-size=\"10.00\">fc2.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"275\" y=\"-398\" font-family=\"monospace\" font-size=\"10.00\"> (32, 64)</text>\n",
       "</g>\n",
       "<!-- 13280311920&#45;&gt;13236213008 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>13280311920&#45;&gt;13236213008</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M275,-390.5C275,-381.4 275,-369.89 275,-360.07\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"278.5,-360.34 275,-350.34 271.5,-360.34 278.5,-360.34\"/>\n",
       "</g>\n",
       "<!-- 13236215744 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>13236215744</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"357,-146.25 281,-146.25 281,-125.5 357,-125.5 357,-146.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"319\" y=\"-132.75\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n",
       "</g>\n",
       "<!-- 13236215744&#45;&gt;13237288480 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>13236215744&#45;&gt;13237288480</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M296.47,-125.09C276.76,-116.52 247.89,-103.98 225.65,-94.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"227.29,-91.21 216.72,-90.43 224.5,-97.63 227.29,-91.21\"/>\n",
       "</g>\n",
       "<!-- 13236214640 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>13236214640</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"392,-209.38 292,-209.38 292,-188.62 392,-188.62 392,-209.38\"/>\n",
       "<text text-anchor=\"middle\" x=\"342\" y=\"-195.88\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 13236214640&#45;&gt;13236215744 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>13236214640&#45;&gt;13236215744</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M338.3,-188.18C335.17,-179.84 330.56,-167.61 326.64,-157.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"329.94,-156.01 323.14,-147.89 323.39,-158.48 329.94,-156.01\"/>\n",
       "</g>\n",
       "<!-- 13280305360 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>13280305360</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"400,-285.25 324,-285.25 324,-251.75 400,-251.75 400,-285.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"362\" y=\"-271.75\" font-family=\"monospace\" font-size=\"10.00\">fc3.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"362\" y=\"-259\" font-family=\"monospace\" font-size=\"10.00\"> (1, 32)</text>\n",
       "</g>\n",
       "<!-- 13280305360&#45;&gt;13236214640 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>13280305360&#45;&gt;13236214640</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M357.26,-251.5C354.53,-242.3 351.08,-230.64 348.14,-220.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"351.54,-219.87 345.34,-211.27 344.83,-221.86 351.54,-219.87\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x31472e030>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualize the neural net (for reference)\n",
    "from torchviz import make_dot\n",
    "x=torch.randn(1, X_train.shape[1])\n",
    "y=model(x)\n",
    "make_dot(y, params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID      SALEPRICE\n",
      "0    1001   86286.765625\n",
      "1    1002  100186.929688\n",
      "2    1003  283795.843750\n",
      "3    1004  180782.062500\n",
      "4    1005  203483.921875\n",
      "..    ...            ...\n",
      "455  1456  173759.140625\n",
      "456  1457  219339.828125\n",
      "457  1458  221575.015625\n",
      "458  1459  123106.023438\n",
      "459  1460  134942.234375\n",
      "\n",
      "[460 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# X. Load the test data and predict/write to predictions.csv\n",
    "# -----------------------------\n",
    "data_testset = pd.read_csv('test.csv')\n",
    "\n",
    "X_testset = data_testset[top_features].values\n",
    "X_testset = scaler.transform(X_testset)\n",
    "X_testset_tensor = torch.tensor(X_testset, dtype=torch.float32)\n",
    "\n",
    "y_testset_pred = model(X_testset_tensor).detach().numpy()\n",
    "data_testset[\"SALEPRICE\"] = y_testset_pred\n",
    "data_testset[\"ID\"] = data_testset[\"Id\"]\n",
    "print(data_testset.loc[:,['ID', 'SALEPRICE']])\n",
    "data_testset.to_csv(\"predictions.csv\", columns=['ID', 'SALEPRICE'], header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected top 1 features: ['OverallQual']\n",
      "Test Mean Squared Error: 1396494848.0\n",
      "Test MSE (scikit-learn): 1396494633.746641\n",
      "In-sample R^2: 0.6868\n",
      "Out-of-sample R^2: 0.6656\n",
      "\n",
      "Selected top 2 features: ['OverallQual', 'GrLivArea']\n",
      "Test Mean Squared Error: 1079591296.0\n",
      "Test MSE (scikit-learn): 1079591304.9249659\n",
      "In-sample R^2: 0.7780\n",
      "Out-of-sample R^2: 0.7415\n",
      "\n",
      "Selected top 3 features: ['OverallQual', 'GrLivArea', 'GarageCars']\n",
      "Test Mean Squared Error: 902517376.0\n",
      "Test MSE (scikit-learn): 902517316.6596829\n",
      "In-sample R^2: 0.7974\n",
      "Out-of-sample R^2: 0.7839\n",
      "\n",
      "Selected top 4 features: ['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea']\n",
      "Test Mean Squared Error: 921514048.0\n",
      "Test MSE (scikit-learn): 921514014.3214035\n",
      "In-sample R^2: 0.8041\n",
      "Out-of-sample R^2: 0.7793\n",
      "\n",
      "Selected top 5 features: ['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF']\n",
      "Test Mean Squared Error: 893399040.0\n",
      "Test MSE (scikit-learn): 893399035.6906488\n",
      "In-sample R^2: 0.8276\n",
      "Out-of-sample R^2: 0.7861\n",
      "\n",
      "Selected top 6 features: ['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF', '1stFlrSF']\n",
      "Test Mean Squared Error: 909501568.0\n",
      "Test MSE (scikit-learn): 909501557.5166638\n",
      "In-sample R^2: 0.8257\n",
      "Out-of-sample R^2: 0.7822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Used to find the seemingly best number of independent variables => Best out-of-sample R^2 at NVAR=5\n",
    "def iterateOverNvar(minN, maxN)\n",
    "    for NVAR in range(minN,maxN+1):\n",
    "        # -----------------------------\n",
    "        # 3. Feature Selection\n",
    "        # -----------------------------\n",
    "        # Compute the correlation matrix using only the cleaned numeric data.\n",
    "        corr_matrix = data_clean.corr()\n",
    "        \n",
    "        # Compute absolute correlations of features with the target and drop the target itself.\n",
    "        target_corr = corr_matrix['SalePrice'].drop('SalePrice').abs().sort_values(ascending=False)\n",
    "        # target_corr = corr_matrix['SalePrice'].drop('SalePrice').drop(\"GarageArea\").abs().sort_values(ascending=False)\n",
    "        # print(target_corr)\n",
    "        \n",
    "        # Select only the top NVAR features with the highest correlation with 'SalesPrice'\n",
    "        top_features = target_corr.head(NVAR).index\n",
    "        print(f\"Selected top {NVAR} features:\", list(top_features))\n",
    "        \n",
    "        # Define input features (X) and target variable (y).\n",
    "        X = data_clean[top_features].values\n",
    "        y = data_clean['SalePrice'].values.reshape(-1, 1)\n",
    "        \n",
    "        # -----------------------------\n",
    "        # 4. Data Preprocessing\n",
    "        # -----------------------------\n",
    "        # Split the data into training and testing sets.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Standardize features to improve training stability.\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Convert the numpy arrays to PyTorch tensors.\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "        y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "        \n",
    "        # Create a TensorDataset and DataLoader for batch processing.\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        \n",
    "        # -----------------------------\n",
    "        # 5. Define the Neural Network Model\n",
    "        # -----------------------------\n",
    "        class HousePriceModel(nn.Module):\n",
    "            def __init__(self, input_dim):\n",
    "                super(HousePriceModel, self).__init__()\n",
    "                self.fc1 = nn.Linear(input_dim, 64)\n",
    "                self.fc2 = nn.Linear(64, 32)\n",
    "                self.fc3 = nn.Linear(32, 1)  # Output layer for regression\n",
    "                self.relu = nn.ReLU()\n",
    "            \n",
    "            def forward(self, x):\n",
    "                x = self.relu(self.fc1(x))\n",
    "                x = self.relu(self.fc2(x))\n",
    "                x = self.fc3(x)\n",
    "                return x\n",
    "        \n",
    "        # Use GPU if available\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model = HousePriceModel(input_dim=X_train.shape[1]).to(device)\n",
    "        \n",
    "        # -----------------------------\n",
    "        # 6. Set Up Loss Function and Optimizer\n",
    "        # -----------------------------\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        # -----------------------------\n",
    "        # 7. Train the Model\n",
    "        # -----------------------------\n",
    "        num_epochs = 1000\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for batch_X, batch_y in train_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item() * batch_X.size(0)\n",
    "            \n",
    "            epoch_loss = running_loss / len(train_dataset)\n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                pass\n",
    "                # print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "        \n",
    "        # -----------------------------\n",
    "        # 8. Evaluate the Model\n",
    "        # -----------------------------\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = model(X_test_tensor.to(device))\n",
    "            test_loss = criterion(predictions, y_test_tensor.to(device)).item()\n",
    "            print(\"Test Mean Squared Error:\", test_loss)\n",
    "            \n",
    "        # Optionally, to evaluate using scikit-learn's MSE:\n",
    "        predictions_np = predictions.cpu().numpy()\n",
    "        mse = mean_squared_error(y_test, predictions_np)\n",
    "        print(\"Test MSE (scikit-learn):\", mse)\n",
    "        # Test Mean Squared Error: 935741376.0\n",
    "        \n",
    "        # Calculate in-sample R^2 value\n",
    "        y_train_pred = model(X_train_tensor).detach().numpy()\n",
    "        ss_total = np.sum((y_train - np.mean(y_train))**2)\n",
    "        ss_residual = np.sum((y_train - y_train_pred)**2)\n",
    "        r2_score = 1 - (ss_residual / ss_total)\n",
    "        print(f'In-sample R^2: {r2_score:.4f}')\n",
    "        \n",
    "        # Calculate out-of-sample R^2 value\n",
    "        y_test_pred = model(X_test_tensor).detach().numpy()\n",
    "        ss_total_test = np.sum((y_test - np.mean(y_test))**2)\n",
    "        ss_residual_test = np.sum((y_test - y_test_pred)**2)\n",
    "        r2_score_test = 1 - (ss_residual_test / ss_total_test)\n",
    "        print(f'Out-of-sample R^2: {r2_score_test:.4f}')\n",
    "        print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
